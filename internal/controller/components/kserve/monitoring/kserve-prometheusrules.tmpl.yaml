apiVersion: monitoring.rhobs/v1
kind: PrometheusRule
metadata:
  name: kserve-prometheusrules
  namespace: {{.Namespace}}
spec:
  groups:
      - name: SLOs-probe_success_kserve
        rules:
        - alert: Kserve Controller Probe Success Burn Rate
          annotations:
            message: 'High error budget burn for {{`{{`}}$labels.instance{{`}}`}} (current value: {{`{{`}}$value{{`}}`}} ).'
            summary: Kserve Controller Probe Success Burn Rate
          expr: |
            sum(probe_success:burnrate5m{instance=~"kserve-controller-manager"}) by (instance) > (14.40 * (1-0.98000))
            and
            sum(probe_success:burnrate1h{instance=~"kserve-controller-manager"}) by (instance) > (14.40 * (1-0.98000))
          for: 2m
          labels:
            severity: critical
        - alert: Kserve Controller Probe Success Burn Rate
          annotations:
            message: 'High error budget burn for {{`{{`}}$labels.instance{{`}}`}} (current value: {{`{{`}}$value{{`}}`}} ).'
            summary: Kserve Controller Probe Success Burn Rate
          expr: |
            sum(probe_success:burnrate30m{instance=~"kserve-controller-manager"}) by (instance) > (6.00 * (1-0.98000))
            and
            sum(probe_success:burnrate6h{instance=~"kserve-controller-manager"}) by (instance) > (6.00 * (1-0.98000))
          for: 15m
          labels:
            severity: critical
        - alert: Kserve Controller Probe Success Burn Rate
          annotations:
            message: 'High error budget burn for {{`{{`}}$labels.instance{{`}}`}} (current value: {{`{{`}}$value{{`}}`}} ).'
            summary: Kserve Controller Probe Success Burn Rate
          expr: |
            sum(probe_success:burnrate2h{instance=~"kserve-controller-manager"}) by (instance) > (3.00 * (1-0.98000))
            and
            sum(probe_success:burnrate1d{instance=~"kserve-controller-manager"}) by (instance) > (3.00 * (1-0.98000))
          for: 1h
          labels:
            severity: warning

      # RecordingRules for Kserve Controller Manager
      - name: SLOs - Kserve Controller Manager
        rules:
        - expr: |
            absent(up{job=~'Kserve Controller Manager'}) * 0 or vector(1)
          labels:
            instance: kserve-controller-manager
          record: probe_success
        - expr: |
            1 - min(avg_over_time(probe_success{instance="kserve-controller-manager"}[1d]))
          labels:
            instance: kserve-controller-manager
          record: probe_success:burnrate1d
        - expr: |
            1 - min(avg_over_time(probe_success{instance="kserve-controller-manager"}[1h]))
          labels:
            instance: kserve-controller-manager
          record: probe_success:burnrate1h
        - expr: |
            1 - min(avg_over_time(probe_success{instance="kserve-controller-manager"}[2h]))
          labels:
            instance: kserve-controller-manager
          record: probe_success:burnrate2h
        - expr: |
            1 - min(avg_over_time(probe_success{instance="kserve-controller-manager"}[30m]))
          labels:
            instance: kserve-controller-manager
          record: probe_success:burnrate30m
        - expr: |
            1 - min(avg_over_time(probe_success{instance="kserve-controller-manager"}[3d]))
          labels:
            instance: kserve-controller-manager
          record: probe_success:burnrate3d
        - expr: |
            1 - min(avg_over_time(probe_success{instance="kserve-controller-manager"}[5m]))
          labels:
            instance: kserve-controller-manager
          record: probe_success:burnrate5m
        - expr: |
            1 - min(avg_over_time(probe_success{instance="kserve-controller-manager"}[6h]))
          labels:
            instance: kserve-controller-manager
          record: probe_success:burnrate6h

      - name: kserve-maas.rules
        rules:
          # 1) Recording rule: per-model QPS over 5 minutes
          - record: kserve:maas_request_qps:rate5m
            expr: |
              sum by (namespace, service, model) (
                rate(request_predict_seconds_count[5m])
              )

          # 2) Recording rule: authorized calls rate over 5 minutes
          - record: kserve:maas_authorized_calls:rate5m
            expr: |
              sum by (namespace, service, model) (
                rate(authorized_calls[5m])
              )

          # 3) Recording rule: authorized hits rate over 5 minutes
          - record: kserve:maas_authorized_hits:rate5m
            expr: |
              sum by (namespace, service, model) (
                rate(authorized_hits[5m])
              )

          # 4) Recording rule: limited calls rate over 5 minutes
          - record: kserve:maas_limited_calls:rate5m
            expr: |
              sum by (namespace, service, model) (
                rate(limited_calls[5m])
              )

          # 5) Recording rule: quota limit hit ratio (limited_calls / authorized_calls)
          - record: kserve:maas_quota_limit_hit_ratio:rate5m
            expr: |
              (
                sum by (namespace, service, model) (
                  rate(limited_calls[5m])
                )
                /
                sum by (namespace, service, model) (
                  rate(authorized_calls[5m])
                )
              )

          # 6) Alert: high prediction latency (p95 > 2s for 5m)
          - alert: KServeMaaSHighLatencyP95
            expr: |
              histogram_quantile(
                0.95,
                sum by (le, namespace, service, model) (
                  rate(request_predict_seconds_bucket[5m])
                )
              ) > 2
            for: 5m
            labels:
              severity: warning
              component: kserve
              subsystem: maas
            annotations:
              message: '95th percentile prediction latency for model {{`{{`}}$labels.model{{`}}`}} in namespace {{`{{`}}$labels.namespace{{`}}`}} is above 2 seconds for at least 5 minutes.'
              summary: "KServe/MaaS high prediction latency (p95 > 2s)"

          # 7) Alert: high non-success response ratio (>5% for 10m)
          - alert: KServeMaaSHighErrorRate
            expr: |
              (
                sum by (namespace, service, model) (
                  rate(request_predict_seconds_count{response_code!~"2..|3.."}[10m])
                )
                /
                sum by (namespace, service, model) (
                  rate(request_predict_seconds_count[10m])
                )
              ) > 0.05
            for: 10m
            labels:
              severity: warning
              component: kserve
              subsystem: maas
            annotations:
              message: 'Error rate for model {{`{{`}}$labels.model{{`}}`}} in namespace {{`{{`}}$labels.namespace{{`}}`}} is above 5% over the last 10 minutes.'
              summary: "KServe/MaaS high error rate (>5%)"

          # 8) Alert: high quota limit hit rate (>10% for 10m)
          - alert: KServeMaaSHighQuotaLimitHitRate
            expr: |
              (
                sum by (namespace, service, model) (
                  rate(limited_calls[10m])
                )
                /
                sum by (namespace, service, model) (
                  rate(authorized_calls[10m])
                )
              ) > 0.10
              and
              sum by (namespace, service, model) (
                rate(authorized_calls[10m])
              ) > 0
            for: 10m
            labels:
              severity: warning
              component: kserve
              subsystem: maas
            annotations:
              message: 'Quota limit hit rate for model {{`{{`}}$labels.model{{`}}`}} in namespace {{`{{`}}$labels.namespace{{`}}`}} is above 10% over the last 10 minutes. This indicates requests are being rate-limited frequently.'
              summary: "KServe/MaaS high quota limit hit rate (>10%)"

          # 9) Alert: sustained quota limit hits (>50% for 30m)
          - alert: KServeMaaSSustainedQuotaLimitHits
            expr: |
              (
                sum by (namespace, service, model) (
                  rate(limited_calls[30m])
                )
                /
                sum by (namespace, service, model) (
                  rate(authorized_calls[30m])
                )
              ) > 0.50
              and
              sum by (namespace, service, model) (
                rate(authorized_calls[30m])
              ) > 0
            for: 30m
            labels:
              severity: critical
              component: kserve
              subsystem: maas
            annotations:
              message: 'Quota limit hit rate for model {{`{{`}}$labels.model{{`}}`}} in namespace {{`{{`}}$labels.namespace{{`}}`}} is above 50% over the last 30 minutes. This indicates severe rate limiting that may require quota adjustment.'
              summary: "KServe/MaaS sustained quota limit hits (>50%)"
