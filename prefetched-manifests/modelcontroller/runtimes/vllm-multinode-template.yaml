apiVersion: template.openshift.io/v1
kind: Template
metadata:
  labels:
    opendatahub.io/dashboard: 'false'
    opendatahub.io/ootb: 'true'
  annotations:
    description: vLLM is a high-throughput and memory-efficient inference and serving engine for LLMs
    openshift.io/display-name: vLLM Multi-Node ServingRuntime for KServe
    openshift.io/provider-display-name: Red Hat, Inc.
    tags: rhods,rhoai,kserve,servingruntime,multi-node
    template.openshift.io/documentation-url: https://github.com/opendatahub-io/vllm
    template.openshift.io/long-description: This template defines resources needed to deploy vLLM Multi-Node ServingRuntime with KServe in Red Hat OpenShift AI
    opendatahub.io/modelServingSupport: '["single"]'
    opendatahub.io/apiProtocol: 'REST'
    opendatahub.io/model-type: '["generative"]'
  name: vllm-multinode-runtime-template
objects:
  - apiVersion: serving.kserve.io/v1alpha1
    kind: ServingRuntime
    metadata:
      name: vllm-multinode-runtime
      annotations:
        openshift.io/display-name: vLLM Multi-Node ServingRuntime for KServe
        opendatahub.io/recommended-accelerators: '["nvidia.com/gpu"]'
        opendatahub.io/runtime-version: 'v0.9.1.0'
      labels:
        opendatahub.io/dashboard: 'false'
    spec:
      annotations:
        opendatahub.io/kserve-runtime: 'vllm'
        prometheus.io/port: '8080'
        prometheus.io/path: '/metrics'
      multiModel: false
      supportedModelFormats:
        - autoSelect: true
          name: vLLM
          priority: 2
      containers:
        - name: kserve-container
          image: $(vllm-cuda-image)
          command: 
          - "bash"
          - "-c"
          - |
            export MODEL_NAME=${MODEL_DIR}
            CMD="python3 -m vllm.entrypoints.openai.api_server \
                --distributed-executor-backend ray \
                --model=${MODEL_NAME} \
                --tensor-parallel-size=${TENSOR_PARALLEL_SIZE} \
                --pipeline-parallel-size=${PIPELINE_PARALLEL_SIZE} $0 $@"
            echo "*MultiNode VLLM Runtime Command*"
            echo "$CMD"

            echo ""
            echo "Ray Start"
            ray start --head --disable-usage-stats --include-dashboard false 
            # wait for other node to join
            until [[ $(ray status --address ${RAY_ADDRESS} | grep -c node_) -eq ${PIPELINE_PARALLEL_SIZE} ]]; do
              echo "Waiting..."
              sleep 1
            done
            ray status --address ${RAY_ADDRESS}

            exec $CMD
          args:
          - --served-model-name={{.Name}}
          - --port=8080 
          env:
            - name: RAY_USE_TLS
              value: '1'
            - name: RAY_TLS_SERVER_CERT
              value: '/etc/ray/tls/tls.pem'
            - name: RAY_TLS_SERVER_KEY
              value: '/etc/ray/tls/tls.pem'
            - name: RAY_TLS_CA_CERT
              value: '/etc/ray/tls/ca.crt'
            - name: RAY_PORT
              value: '6379'
            - name: RAY_ADDRESS
              value: 127.0.0.1:6379
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: VLLM_NO_USAGE_STATS
              value: '1'
            - name: HOME
              value: /tmp
            - name: HF_HOME
              value: /tmp/hf_home
          resources:
            limits:
              cpu: '16'
              memory: 48Gi
            requests:
              cpu: '8'
              memory: 24Gi
          volumeMounts:
            - name: shm
              mountPath: /dev/shm
          livenessProbe:
            failureThreshold: 2
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 15
            exec:
              command:
                - bash
                - -c
                - |
                  # Check if the registered ray nodes count is greater or the same than PIPELINE_PARALLEL_SIZE
                  registered_node_count=$(ray status --address ${RAY_ADDRESS} | grep -c node_)
                  if [[ ! ${registered_node_count} -ge "${PIPELINE_PARALLEL_SIZE}" ]]; then
                    echo "Unhealthy - Registered nodes count (${registered_node_count}) must not be less PIPELINE_PARALLEL_SIZE (${PIPELINE_PARALLEL_SIZE})."
                    exit 1
                  fi     

                  # Check model health
                  health_check=$(curl -o /dev/null -s -w "%{http_code}\n" http://localhost:8080/health)
                  if [[ ${health_check} != 200 ]]; then
                    echo "Unhealthy - vLLM Runtime Health Check failed." 
                    exit 1
                  fi
          readinessProbe:
            failureThreshold: 2
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 15
            exec:
              command:
                - bash
                - -c
                - |
                  # Check model health 
                  health_check=$(curl -o /dev/null -s -w "%{http_code}\n" http://localhost:8080/health)
                  if [[ ${health_check} != 200 ]]; then
                    echo "Unhealthy - vLLM Runtime Health Check failed." 
                    exit 1
                  fi
          startupProbe:
            failureThreshold: 40
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 30
            initialDelaySeconds: 20
            exec:
              command:
                - bash
                - -c
                - |
                  # This need when head node have issues and restarted.
                  # It will wait for new worker node.                     
                  registered_node_count=$(ray status --address ${RAY_ADDRESS} | grep -c node_)
                  if [[ ! ${registered_node_count} -ge "${PIPELINE_PARALLEL_SIZE}" ]]; then
                    echo "Unhealthy - Registered nodes count (${registered_node_count}) must not be less PIPELINE_PARALLEL_SIZE (${PIPELINE_PARALLEL_SIZE})."
                    exit 1
                  fi

                  # Double check to make sure Model is ready to serve.
                  for i in 1 2; do                    
                    # Check model health
                    health_check=$(curl -o /dev/null -s -w "%{http_code}\n" http://localhost:8080/health)
                    if [[ ${health_check} != 200 ]]; then
                      echo "Unhealthy - vLLM Runtime Health Check failed." 
                      exit 1
                    fi
                  done
          ports:
            - containerPort: 8080
              name: http
              protocol: TCP
      volumes:
        - name: shm
          emptyDir:
            medium: Memory
            sizeLimit: 12Gi
      workerSpec:
        pipelineParallelSize: 2
        tensorParallelSize: 1
        containers:
          - name: worker-container
            image: $(vllm-cuda-image)
            command:
            - "bash"
            - "-c"
            - |
              export RAY_HEAD_ADDRESS="${HEAD_SVC}.${POD_NAMESPACE}.svc.cluster.local:6379"

              SECONDS=0

              while true; do
                if (( SECONDS <= 240 )); then
                  if ray health-check --address "${RAY_HEAD_ADDRESS}" > /dev/null 2>&1; then
                    echo "Global Control Service (GCS) is ready."
                    break
                  fi
                  echo "$SECONDS seconds elapsed: Waiting for Global Control Service (GCS) to be ready."
                else
                  if ray health-check --address "${RAY_HEAD_ADDRESS}"; then
                    echo "Global Control Service (GCS) is ready. Any error messages above can be safely ignored."
                    break
                  fi
                  echo "$SECONDS seconds elapsed: Still waiting for Global Control Service (GCS) to be ready."
                  echo "For troubleshooting, refer to the FAQ at https://docs.ray.io/en/master/cluster/kubernetes/troubleshooting/troubleshooting.html#kuberay-troubleshootin-guides"
                fi

                sleep 5
              done

              echo "Attempting to connect to Ray cluster at $RAY_HEAD_ADDRESS ..."
              ray start --address="${RAY_HEAD_ADDRESS}" --block
            env:
              - name: RAY_USE_TLS
                value: '1'
              - name: RAY_TLS_SERVER_CERT
                value: '/etc/ray/tls/tls.pem'
              - name: RAY_TLS_SERVER_KEY
                value: '/etc/ray/tls/tls.pem'
              - name: RAY_TLS_CA_CERT
                value: '/etc/ray/tls/ca.crt'
              - name: POD_NAME
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.name
              - name: POD_NAMESPACE
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.namespace
              - name: POD_IP
                valueFrom:
                  fieldRef:
                    fieldPath: status.podIP
            resources:
              limits:
                cpu: '16'
                memory: 48Gi
              requests:
                cpu: '8'
                memory: 24Gi
            volumeMounts:
              - name: shm
                mountPath: /dev/shm
            livenessProbe:
              failureThreshold: 2
              periodSeconds: 5
              successThreshold: 1
              timeoutSeconds: 15
              exec:
                command:
                  - bash
                  - -c
                  - |
                    # Check if the registered nodes count matches PIPELINE_PARALLEL_SIZE
                    registered_node_count=$(ray status --address ${HEAD_SVC}.${POD_NAMESPACE}.svc.cluster.local:6379 | grep -c node_)
                    if [[ ! ${registered_node_count} -ge "${PIPELINE_PARALLEL_SIZE}" ]]; then
                      echo "Unhealthy - Registered nodes count (${registered_node_count}) must not be less PIPELINE_PARALLEL_SIZE (${PIPELINE_PARALLEL_SIZE})."
                      exit 1
                    fi
            startupProbe:
              failureThreshold: 40
              periodSeconds: 30
              successThreshold: 1
              timeoutSeconds: 30
              initialDelaySeconds: 20
              exec:
                command:
                  - /bin/sh
                  - -c
                  - |
                    registered_node_count=$(ray status --address ${HEAD_SVC}.${POD_NAMESPACE}.svc.cluster.local:6379 | grep -c node_)
                    if [[ ! ${registered_node_count} -ge "${PIPELINE_PARALLEL_SIZE}" ]]; then
                      echo "Unhealthy - Registered nodes count (${registered_node_count}) must not be less PIPELINE_PARALLEL_SIZE (${PIPELINE_PARALLEL_SIZE})."
                      exit 1
                    fi  

                    # Double check to make sure Model is ready to serve.
                    for i in 1 2; do
                      # Check model health
                      model_health_check=$(curl -s ${HEAD_SVC}.${POD_NAMESPACE}.svc.cluster.local:8080/v1/models | grep -q '"object":"model"' && echo true || echo false)
                      if [[ "${model_health_check}" == "false" ]]; then
                        echo "Unhealthy - vLLM Runtime Health Check failed."
                        exit 1
                      fi
                      sleep 10
                    done
        volumes:
          - name: shm
            emptyDir:
              medium: Memory
              sizeLimit: 12Gi
